{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1b3d5f-1f34-40ec-be88-d780df0320b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08156de6-7d48-4d8f-8713-c0de9828c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime.backend as backend\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858e55c5-b567-4876-b9f1-10317183fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"../models/detect/1/model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eae3a66-9261-432f-a742-0fcbdfcd514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_preparation(image_path, scales, resized_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    print('Original shape:', img.shape)\n",
    "    scales = scales\n",
    "\n",
    "    im_shape = img.shape\n",
    "    target_size = min(scales)\n",
    "    max_size = max(scales)\n",
    "    im_size_x = im_shape[1]\n",
    "    im_size_y = im_shape[0]\n",
    "    im_scale_x = float(scales[1]/im_size_x)\n",
    "    im_scale_y = float(scales[0]/im_size_y)\n",
    "    scales = [im_scale_x, im_scale_y]\n",
    "    print('im_scale:',scales)\n",
    "\n",
    "    resized_img = None\n",
    "    if im_scale_x!=1.0 or im_scale_y!=1.0:\n",
    "        resized_img = cv2.resize(img, None, None, fx=im_scale_x, fy=im_scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imwrite(resized_path, resized_img)\n",
    "    else:\n",
    "        resized_img = img.copy()\n",
    "\n",
    "    print('Resized shape:', resized_img.shape)\n",
    "    resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    aligned = np.transpose(resized_img, (2,0,1)) #HWC->CHW\n",
    "\n",
    "    return aligned, img, scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f084af5c-87a5-4a14-bb5c-c7832658db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_preprocess(img, scales, resized_path):\n",
    "    im_shape = img.shape\n",
    "    target_size = scales[0]\n",
    "    max_size = scales[1]\n",
    "    im_size_min = np.min(im_shape[0:2])\n",
    "    im_size_max = np.max(im_shape[0:2])\n",
    "    im_scale = float(target_size) / float(im_size_min)\n",
    "    if np.round(im_scale * im_size_max) > max_size:\n",
    "        im_scale = float(max_size) / float(im_size_max)\n",
    "    \n",
    "    #print('im_scale:',scales)\n",
    "    scales = [im_scale,im_scale]\n",
    "\n",
    "    resized_img = None\n",
    "    if im_scale!=1.0:\n",
    "        resized_img = cv2.resize(img, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imwrite(resized_path, resized_img)\n",
    "    else:\n",
    "        resized_img = img.copy()\n",
    "\n",
    "    print('Resized shape:', resized_img.shape)\n",
    "    resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    dim_changed = np.transpose(resized_img, (2,0,1)) #HWC->CHW\n",
    "\n",
    "    input_blob = np.expand_dims(dim_changed, axis=0).astype(np.float32)\n",
    "\n",
    "    images_data = []\n",
    "    # filenames = []\n",
    "    # filename = unique_id\n",
    "    images_data.append(input_blob)\n",
    "    # filenames.append(filename)\n",
    "\n",
    "    # return images_data, scales, im_shape\n",
    "    return input_blob, scales, im_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42cc5a98-b84c-4d98-aa88-ed3d90ef2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = '900,900'\n",
    "scales = scales.split(',')\n",
    "scales = [int(scales[0]), int(scales[1])]\n",
    "# im_size=[int(image_size.split(',')[0]), int(image_size.split(',')[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9bc680e-6e3e-4f05-aeba-4087fa1a9b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[900, 900]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d9f179b-9649-4d5e-a35b-6a223463ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './photos/altynbek.jpg'\n",
    "img_name = './resized/' + image_path.split('/')[-1].split('.')[0] + '_resized.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d86b97c-e20b-4c45-86fb-4f28a30e292e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./resized/altynbek_resized.jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0df898e7-0f3f-4a36-89c1-884ffbb0bb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1280, 960, 3)\n",
      "im_scale: [0.9375, 0.703125]\n",
      "Resized shape: (900, 900, 3)\n"
     ]
    }
   ],
   "source": [
    "align, result_img, im_scale = face_preparation(image_path, scales, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e61ddbf-12ce-4a4e-9c52-fbc79f6fb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized shape: (900, 675, 3)\n"
     ]
    }
   ],
   "source": [
    "cv_img = cv2.imread(image_path)\n",
    "blob_img, scale, im_shape = frame_preprocess(cv_img, scales, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6855d57c-de3f-439c-9337-afe2209db829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(onnx_file, input_blob, batching = False):\n",
    "    # if not batching:\n",
    "    #     # ONE INPUT\n",
    "    #     input_blob = np.expand_dims(aligned, axis=0).astype(np.float32) #NCHW\n",
    "    #     # ONE INPUT\n",
    "    # else:\n",
    "    #     # BATCHING\n",
    "    #     input_blob = np.expand_dims(aligned, axis=0).astype(np.float32) #NCHW\n",
    "    #     input_blob = np.squeeze(input_blob)\n",
    "    #     # BATCHING\n",
    "    onnx_model = onnx.load(onnx_file)\n",
    "    ort_session = backend.prepare(onnx_model, 'GPU')\n",
    "    outputs = ort_session.run(input_blob)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2af316ca-2934-4576-b191-b25a2cbbdf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP Error /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1193 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_tensorrt.so with error: libnvinfer.so.8: cannot open shared object file: No such file or directory\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 01:56:44.572348042 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,20,113,113} does not match actual shape of {1,20,113,85} for output face_rpn_landmark_pred_stride8\n",
      "2023-12-17 01:56:44.659391685 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,8,113,113} does not match actual shape of {1,8,113,85} for output face_rpn_bbox_pred_stride8\n",
      "2023-12-17 01:56:45.011036123 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,4,113,113} does not match actual shape of {1,4,113,85} for output face_rpn_cls_prob_reshape_stride8\n",
      "2023-12-17 01:56:45.293606289 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,20,57,57} does not match actual shape of {1,20,57,43} for output face_rpn_landmark_pred_stride16\n",
      "2023-12-17 01:56:45.317452571 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,8,57,57} does not match actual shape of {1,8,57,43} for output face_rpn_bbox_pred_stride16\n",
      "2023-12-17 01:56:45.345160312 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,4,57,57} does not match actual shape of {1,4,57,43} for output face_rpn_cls_prob_reshape_stride16\n",
      "2023-12-17 01:56:45.444520570 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,20,29,29} does not match actual shape of {1,20,29,22} for output face_rpn_landmark_pred_stride32\n",
      "2023-12-17 01:56:45.455361411 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,8,29,29} does not match actual shape of {1,8,29,22} for output face_rpn_bbox_pred_stride32\n",
      "2023-12-17 01:56:45.470216153 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {1,4,29,29} does not match actual shape of {1,4,29,22} for output face_rpn_cls_prob_reshape_stride32\n"
     ]
    }
   ],
   "source": [
    "outputs = get_feature('../models/detect/1/model.onnx', blob_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18bc24-3cd3-4db7-8bac-ad7ba3202a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b90f015f-7b90-47af-8908-622a13e5bb77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], test_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m ort_sess \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mInferenceSession(onnx_model)\n\u001b[1;32m      3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ort_sess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: x\u001b[38;5;241m.\u001b[39mnumpy()})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "ort_sess = ort.InferenceSession(onnx_model)\n",
    "outputs = ort_sess.run(None, {'input': x.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13848d-62ce-4d4a-97a2-3b14d77daba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
